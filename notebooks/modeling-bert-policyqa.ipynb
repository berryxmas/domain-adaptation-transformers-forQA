{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHDJ--Z1ogSI"
      },
      "source": [
        "![Rijksoverheid logo](https://www.rijksoverheid.nl/binaries/content/gallery/rijksoverheid/channel-afbeeldingen/logos/logo-ro.svg)\n",
        "\n",
        "# Dutch Government Policy QA dataset\n",
        "This dataset is open-source and can be found on the open data portal of the [Rijksoverheid](https://www.rijksoverheid.nl/opendata/vac-s). It contains up to 2500 frequently asked questions of Dutch citizens. The questions are concerned with Dutch government policies and contain topics like \"Belasting\", \"Asbest\", or \"Klimaat\".<br>\n",
        "More info about the status and contact information can be found [here](https://data.overheid.nl/dataset/vraag-antwoordcombinaties-van-rijksoverheid-nl#panel-description). <br><br>\n",
        "\n",
        "**PolicyQA Dataset:** <br>\n",
        "Note: The PolicyQA dataset is divided as follows. <br>\n",
        "- Train: 400 samples\n",
        "- Test: 100 samples\n",
        "\n",
        "**How to use:** <br>\n",
        "It is best to use Google Colab and run the notebook to get results. <br><br>\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vql1bCz0ogSK"
      },
      "source": [
        "### In this notebook:\n",
        "- Three Bert-based models are tested and evaluated\n",
        "  - MBert\n",
        "  - Bertje\n",
        "  - Robbert\n",
        "- Hyperparameters are checked and tested"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCvi3R-fogSK"
      },
      "outputs": [],
      "source": [
        "# if using Colab, install necessary libraries\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwx9GsewogSL"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas.io.json import json_normalize\n",
        "import json\n",
        "import time\n",
        "import matplotlib as plt\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWOpWMHSogSL"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twKdFU9FogSL"
      },
      "outputs": [],
      "source": [
        "# add loading data from squad example\n",
        "!mkdir data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQhdeM8uJWyq"
      },
      "source": [
        "In Colab: Add policyqa-test.json and policyqa-train.json to data folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWbyouVbogSM"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HITyuRr3ogSM"
      },
      "outputs": [],
      "source": [
        "# import run squad pipeline from HF\n",
        "%load models/run_squad.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkgohfCvogSN"
      },
      "source": [
        "#### MBert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYz50psAINPW"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: bert-base-multilingual-cased\n",
        "# without training\n",
        "# without domain adaptation\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path bert-base-multilingual-cased  \\\n",
        "    --output_dir models/bert/bert-base-multilingual-cased \\\n",
        "    --data_dir  data \\\n",
        "    --train_file policyqa-train.json   \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --learning_rate 3.6e-06 \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mueGAh3UogSN"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: bert-base-multilingual-cased\n",
        "# with training\n",
        "# without domain adaptation\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path bert-base-multilingual-cased  \\\n",
        "    --output_dir models/bert/bert-base-multilingual-cased \\\n",
        "    --data_dir  data \\\n",
        "    --train_file policyqa-train.json   \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_train   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2T88M1TV05G"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: bert-base-multilingual-cased\n",
        "# without training\n",
        "# with domain adaptation / hyperparameter tuning\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path bert-base-multilingual-cased  \\\n",
        "    --output_dir models/bert/bert-base-multilingual-cased \\\n",
        "    --data_dir  data \\\n",
        "    --train_file policyqa-train.json   \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --learning_rate 3.6e-06 \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XZ8crFYV8nE"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: bert-base-multilingual-cased\n",
        "# with training\n",
        "# with domain adaptation / hyperparameter tuning\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path bert-base-multilingual-cased  \\\n",
        "    --output_dir models/bert/bert-base-multilingual-cased \\\n",
        "    --data_dir  data \\\n",
        "    --train_file policyqa-train.json   \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_train   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --learning_rate 3.6e-06 \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mFkxEbJogSN"
      },
      "source": [
        "##### MBert, finetuned on Dutch SQuAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDDZGg8dq1UD"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: bert-base-multilingual-cased-finetuned-dutch-squad2\n",
        "# without training\n",
        "# without domain adaptation\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path henryk/bert-base-multilingual-cased-finetuned-dutch-squad2  \\\n",
        "    --output_dir models/bert/henryk/bert-base-multilingual-cased-finetuned-dutch-squad2 \\\n",
        "    --data_dir  data \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouo5BscbogSN"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: bert-base-multilingual-cased-finetuned-dutch-squad2\n",
        "# with training\n",
        "# without domain adaptation\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path henryk/bert-base-multilingual-cased-finetuned-dutch-squad2  \\\n",
        "    --output_dir models/bert/henryk/bert-base-multilingual-cased-finetuned-dutch-squad2 \\\n",
        "    --data_dir  data \\\n",
        "    --train_file policyqa-train.json   \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_train   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8cPNkWEWeDV"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: bert-base-multilingual-cased-finetuned-dutch-squad2\n",
        "# without training\n",
        "# with domain adaptation / hyperparameter tuning\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path henryk/bert-base-multilingual-cased-finetuned-dutch-squad2  \\\n",
        "    --output_dir models/bert/henryk/bert-base-multilingual-cased-finetuned-dutch-squad2 \\\n",
        "    --data_dir  data \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --learning_rate 3.6e-06 \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOR8HFbcXRxG"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: bert-base-multilingual-cased-finetuned-dutch-squad2\n",
        "# with training\n",
        "# with domain adaptation / hyperparameter tuning\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path henryk/bert-base-multilingual-cased-finetuned-dutch-squad2  \\\n",
        "    --output_dir models/bert/henryk/bert-base-multilingual-cased-finetuned-dutch-squad2 \\\n",
        "    --data_dir  data \\\n",
        "    --train_file policyqa-train.json   \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_train   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --learning_rate 3.6e-06 \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9EOyLjgogSN"
      },
      "source": [
        "#### Bertje"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUmeMvHrqvrL"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: GroNLP/bert-base-dutch-cased\n",
        "# without training\n",
        "# without domain adaptation\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path GroNLP/bert-base-dutch-cased  \\\n",
        "    --output_dir models/bert/GroNLP/bert-base-dutch-cased \\\n",
        "    --data_dir  data \\\n",
        "    --train_file policyqa-train.json   \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7YLlJRgptZo"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: GroNLP/bert-base-dutch-cased\n",
        "# with training\n",
        "# without domain adaptation\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path GroNLP/bert-base-dutch-cased  \\\n",
        "    --output_dir models/bert/GroNLP/bert-base-dutch-cased \\\n",
        "    --data_dir  data \\\n",
        "    --train_file policyqa-train.json   \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_train   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbmDe1t6XjEY"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: GroNLP/bert-base-dutch-cased\n",
        "# without training\n",
        "# with domain adaptation / hyperparameter tuning\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path GroNLP/bert-base-dutch-cased  \\\n",
        "    --output_dir models/bert/GroNLP/bert-base-dutch-cased \\\n",
        "    --data_dir  data \\\n",
        "    --train_file policyqa-train.json   \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --learning_rate 3.6e-06 \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWjgK3AQXyed"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: GroNLP/bert-base-dutch-cased\n",
        "# with training\n",
        "# with domain adaptation / hyperparameter tuning\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path GroNLP/bert-base-dutch-cased  \\\n",
        "    --output_dir models/bert/GroNLP/bert-base-dutch-cased \\\n",
        "    --data_dir  data \\\n",
        "    --train_file policyqa-train.json   \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_train   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --learning_rate 3.6e-06 \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrLEnRIAogSO"
      },
      "source": [
        "#### Robbert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnTotaNXqpwu"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: pdelobelle/robbert-v2-dutch-base\n",
        "# without training\n",
        "# without domain adaptation\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path pdelobelle/robbert-v2-dutch-base  \\\n",
        "    --output_dir models/bert/pdelobelle/robbert-v2-dutch-base \\\n",
        "    --data_dir  data \\\n",
        "    --train_file policyqa-train.json   \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYXuz1T5qZq6"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: pdelobelle/robbert-v2-dutch-base\n",
        "# with training\n",
        "# without domain adaptation\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path pdelobelle/robbert-v2-dutch-base  \\\n",
        "    --output_dir models/bert/pdelobelle/robbert-v2-dutch-base \\\n",
        "    --data_dir  data \\\n",
        "    --train_file policyqa-train.json   \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_train   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5h7mHQquYohH"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: pdelobelle/robbert-v2-dutch-base\n",
        "# without training\n",
        "# with domain adaptation / hyperparameter tuning\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path pdelobelle/robbert-v2-dutch-base  \\\n",
        "    --output_dir models/bert/pdelobelle/robbert-v2-dutch-base \\\n",
        "    --data_dir  data \\\n",
        "    --train_file policyqa-train.json   \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --learning_rate 3.6e-06 \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3iKqWw2YqWz"
      },
      "outputs": [],
      "source": [
        "##########\n",
        "# model: pdelobelle/robbert-v2-dutch-base\n",
        "# with training\n",
        "# with domain adaptation / hyperparameter tuning\n",
        "##########\n",
        "!python /content/run_squad.py  \\\n",
        "    --model_type bert   \\\n",
        "    --model_name_or_path pdelobelle/robbert-v2-dutch-base  \\\n",
        "    --output_dir models/bert/pdelobelle/robbert-v2-dutch-base \\\n",
        "    --data_dir  data \\\n",
        "    --train_file policyqa-train.json   \\\n",
        "    --predict_file policyqa-test.json   \\\n",
        "    --do_train   \\\n",
        "    --do_eval   \\\n",
        "    --do_lower_case  \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --learning_rate 3.6e-06 \\\n",
        "    --per_gpu_eval_batch_size 12   \\\n",
        "    --max_seq_length 384   \\\n",
        "    --doc_stride 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGxrc4kLogSO"
      },
      "source": [
        "### Hyperparameter tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lASO_4V0OSes"
      },
      "outputs": [],
      "source": [
        "# import model\n",
        "from transformers import AutoModel\n",
        "\n",
        "model = AutoModel.from_pretrained(\"henryk/bert-base-multilingual-cased-finetuned-dutch-squad2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AntbzFlNOUVE"
      },
      "outputs": [],
      "source": [
        "# function for finding optimal hyperparameters using LLRD\n",
        "def AdamW_LLRD(model):\n",
        "    \n",
        "    opt_parameters = []    # To be passed to the optimizer (only parameters of the layers you want to update).\n",
        "    named_parameters = list(model.named_parameters()) \n",
        "        \n",
        "    # According to AAAMLP book by A. Thakur, we generally do not use any decay \n",
        "    # for bias and LayerNorm.weight layers.\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    init_lr = 3.5e-6 \n",
        "    head_lr = 3.6e-6\n",
        "    lr = init_lr\n",
        "    \n",
        "    # === Pooler and regressor ======================================================  \n",
        "    \n",
        "    params_0 = [p for n,p in named_parameters if (\"pooler\" in n or \"regressor\" in n) \n",
        "                and any(nd in n for nd in no_decay)]\n",
        "    params_1 = [p for n,p in named_parameters if (\"pooler\" in n or \"regressor\" in n)\n",
        "                and not any(nd in n for nd in no_decay)]\n",
        "    \n",
        "    head_params = {\"params\": params_0, \"lr\": head_lr, \"weight_decay\": 0.0}    \n",
        "    opt_parameters.append(head_params)\n",
        "        \n",
        "    head_params = {\"params\": params_1, \"lr\": head_lr, \"weight_decay\": 0.01}    \n",
        "    opt_parameters.append(head_params)\n",
        "                \n",
        "    # === 12 Hidden layers ==========================================================\n",
        "    \n",
        "    for layer in range(11,-1,-1):        \n",
        "        params_0 = [p for n,p in named_parameters if f\"encoder.layer.{layer}.\" in n \n",
        "                    and any(nd in n for nd in no_decay)]\n",
        "        params_1 = [p for n,p in named_parameters if f\"encoder.layer.{layer}.\" in n \n",
        "                    and not any(nd in n for nd in no_decay)]\n",
        "        \n",
        "        layer_params = {\"params\": params_0, \"lr\": lr, \"weight_decay\": 0.0}\n",
        "        opt_parameters.append(layer_params)   \n",
        "                            \n",
        "        layer_params = {\"params\": params_1, \"lr\": lr, \"weight_decay\": 0.01}\n",
        "        opt_parameters.append(layer_params)       \n",
        "        \n",
        "        lr *= 0.9     \n",
        "        \n",
        "    # === Embeddings layer ==========================================================\n",
        "    \n",
        "    params_0 = [p for n,p in named_parameters if \"embeddings\" in n \n",
        "                and any(nd in n for nd in no_decay)]\n",
        "    params_1 = [p for n,p in named_parameters if \"embeddings\" in n\n",
        "                and not any(nd in n for nd in no_decay)]\n",
        "    \n",
        "    embed_params = {\"params\": params_0, \"lr\": lr, \"weight_decay\": 0.0} \n",
        "    opt_parameters.append(embed_params)\n",
        "        \n",
        "    embed_params = {\"params\": params_1, \"lr\": lr, \"weight_decay\": 0.01} \n",
        "    opt_parameters.append(embed_params)        \n",
        "    \n",
        "    return transformers.AdamW(opt_parameters, lr=init_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tiRwt0JLOgD3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/z8/mnh7b0x15b73wxpj_pgc93vr0000gn/T/ipykernel_25315/2072669489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAdamW_LLRD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "AdamW_LLRD(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYKz6NdFOkTV"
      },
      "source": [
        "Using this approach, we checked the optimal hyperparameters for every model. <br>\n",
        "Due to time constraints and computational power, not all options were tested. <br>\n",
        "Testing of all optimal hyperparameter groups can be seen as Future Work."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "modeling-bert-policyqa.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
