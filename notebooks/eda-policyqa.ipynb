{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rijksoverheid logo](https://www.rijksoverheid.nl/binaries/content/gallery/rijksoverheid/channel-afbeeldingen/logos/logo-ro.svg)\n",
    "\n",
    "# Dutch Government Policy QA dataset\n",
    "This dataset is open-source and can be found on the open data portal of the [Rijksoverheid](https://www.rijksoverheid.nl/opendata/vac-s). It contains up to 2500 frequently asked questions of Dutch citizens. The questions are concerned with Dutch government policies and contain topics like \"Belasting\", \"Asbest\", or \"Klimaat\".<br>\n",
    "More info about the status and contact information can be found [here](https://data.overheid.nl/dataset/vraag-antwoordcombinaties-van-rijksoverheid-nl#panel-description). <br><br>\n",
    "\n",
    "**How to use:** <br>\n",
    "It is best to use Google Colab and run the notebook to get results.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/berryyblom/domain-adaptation-transformers-forQA/blob/main/notebooks/eda-policyqa.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook:\n",
    "- The Dutch policy QA data is imported via api with a crawler\n",
    "- Initial EDA is performed to check the size, completeness, and volume\n",
    "- The neccessary columns are exported as a csv\n",
    "- A short answer is retrieved manually from the context\n",
    "- Extra EDA is performed with on the final dataset\n",
    "- The PolicyQA dataset is converted to the correct input for the QA model by using our DF to JSON converter\n",
    "- The PolicyQA dataset in JSON format is used as input for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using Colab, install necessary libraries\n",
    "%pip install transformers\n",
    "!python -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import time\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "First the data is imported using crawler.py <br>\n",
    "Then the data is checked for volume, completeness etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run crawler\n",
    "!python3 /scripts/crawler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv\n",
    "dfraw = pd.read_csv('../data/temp/policyqa-raw.csv')\n",
    "dfraw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial EDA\n",
    "EDA performed on the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check info\n",
    "dfraw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfraw['content'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw conclusion\n",
    "* By inspecting the data we can see the actual answer does only appear in the Introduction column for around 50% of the time.\n",
    "* The actual answer is always in the Introduction column and the Content column is supplementary to the answer.\n",
    "* Therefor the data is exported with the necessary columns\n",
    "* We add supplementary annotations by adding a short answer, which is derived from the Introduction column (the actual answer, supplied by domain experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take first 7 columns\n",
    "dfraw = dfraw.iloc[:, 0:7]\n",
    "# Remove column 3 and 4\n",
    "dfraw = dfraw.drop(columns=[\"canonical\", \"dataurl\"])\n",
    "# Export to csv\n",
    "dfraw.to_csv('policyqa-raw.csv', encoding = 'utf-8-sig') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "The annotated data is added manually. <br>\n",
    "To convert the annotated data to a clean dataset, we call scripts/converter.py\n",
    "This script:\n",
    "- removes non-alphanumeric characters\n",
    "- add all answer start character positions\n",
    "- converts the Dataframe to the correct model input, which is saved at data/dataV3.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run crawler\n",
    "!python3 /scripts/converter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read annotated cleaned csv\n",
    "df = pd.read_csv('../data/temp/policyqa-annotated-clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first 2 columns\n",
    "df = df.iloc[: , 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charts for dataset statistics\n",
    "- Number of characters\n",
    "- Number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_character_length_histogram(text):\n",
    "    text.str.len().\\\n",
    "        hist().set(xlabel='Character length', ylabel='Count', title='Character length histogram (Context)')\n",
    "\n",
    "plot_character_length_histogram(df['introductioncontent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows that questions range from 10 to 100 characters and generally, it is between 30 and 70 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_character_length_histogram(df['introductioncontent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram shows that questions range from 300 to 5800 characters and generally, it is between 900 and 1900 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question'].str.split().\\\n",
    "    map(lambda x: len(x)).\\\n",
    "    hist()\n",
    "\n",
    "# we can see that the number of words range from 3 to 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question'].str.split().\\\n",
    "   apply(lambda x : [len(i) for i in x]). \\\n",
    "   map(lambda x: np.mean(x)).hist()\n",
    "\n",
    "# The average word lenght is 5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop=set(stopwords.words('dutch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "new= df['question'].str.split()\n",
    "new=new.values.tolist()\n",
    "corpus=[word for i in new for word in i]\n",
    "\n",
    "from collections import defaultdict\n",
    "dic=defaultdict(int)\n",
    "for word in corpus:\n",
    "    if word in stop:\n",
    "        dic[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_stopwords_barchart(text):\n",
    "    stop=set(stopwords.words('dutch'))\n",
    "    \n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "    from collections import defaultdict\n",
    "    dic=defaultdict(int)\n",
    "    for word in corpus:\n",
    "        if word in stop:\n",
    "            dic[word]+=1\n",
    "            \n",
    "    top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "    x,y=zip(*top)\n",
    "    plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_stopwords_barchart(df['question'])\n",
    "# We can see that stopwords like Ik (I), een (a), mijn (my), etc. are the most frequent stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Snippet for Top Non-Stopwords Barchart\n",
    "\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from collections import  Counter\n",
    "\n",
    "def plot_top_non_stopwords_barchart(text):\n",
    "    stop=set(stopwords.words('dutch'))\n",
    "    \n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "\n",
    "    counter=Counter(corpus)\n",
    "    most=counter.most_common()\n",
    "    x, y=[], []\n",
    "    for word,count in most[:40]:\n",
    "        if (word not in stop):\n",
    "            x.append(word)\n",
    "            y.append(count)\n",
    "            \n",
    "    sns.barplot(x=y,y=x).set(title='Top Non-Stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_non_stopwords_barchart(df['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_non_stopwords_barchart(df['introductioncontent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see paragraph and paragraphtitle are common words. These do not add any meaning to the text, so let's remove them. Also the colon (:) and the word title do not add meaning to the text, so we remove those words as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['introductioncontent'] = df['introductioncontent'].str.replace(r'paragraph', '', regex=True)\n",
    "df['introductioncontent'] = df['introductioncontent'].str.replace(r'paragraphtitle', '', regex=True)\n",
    "df['introductioncontent'] = df['introductioncontent'].str.replace(r':', '', regex=True)\n",
    "df['introductioncontent'] = df['introductioncontent'].str.replace(r'title', '', regex=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fba33e78b77f025177f80ea29759b55d5960913694c1540010dc608131b64ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
