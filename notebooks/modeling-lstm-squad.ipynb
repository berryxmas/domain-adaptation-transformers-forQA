{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af9722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:20:39.386386Z",
     "iopub.status.busy": "2022-06-20T23:20:39.384672Z",
     "iopub.status.idle": "2022-06-20T23:20:40.175834Z",
     "shell.execute_reply": "2022-06-20T23:20:40.176716Z",
     "shell.execute_reply.started": "2022-06-20T22:14:32.329338Z"
    },
    "id": "LMGpLvYNKR78",
    "outputId": "34d0396a-e705-4c18-bfe2-4c8d3ddd8b0c",
    "papermill": {
     "duration": 0.842286,
     "end_time": "2022-06-20T23:20:40.177006",
     "exception": false,
     "start_time": "2022-06-20T23:20:39.334720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba46af",
   "metadata": {
    "id": "lP-9tyjdylTg",
    "papermill": {
     "duration": 0.043542,
     "end_time": "2022-06-20T23:20:40.268101",
     "exception": false,
     "start_time": "2022-06-20T23:20:40.224559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a133ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:20:40.358949Z",
     "iopub.status.busy": "2022-06-20T23:20:40.358019Z",
     "iopub.status.idle": "2022-06-20T23:21:36.735824Z",
     "shell.execute_reply": "2022-06-20T23:21:36.735287Z",
     "shell.execute_reply.started": "2022-06-20T22:14:33.162298Z"
    },
    "id": "Bm6QVw_hzHB7",
    "papermill": {
     "duration": 56.423838,
     "end_time": "2022-06-20T23:21:36.735962",
     "exception": false,
     "start_time": "2022-06-20T23:20:40.312124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tqdm --upgrade >> /dev/null 2>&1\n",
    "!pip install spacy --upgrade >> /dev/null 2>&1\n",
    "!python -m spacy download en >> /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febefe3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:21:36.835029Z",
     "iopub.status.busy": "2022-06-20T23:21:36.834284Z",
     "iopub.status.idle": "2022-06-20T23:21:42.478831Z",
     "shell.execute_reply": "2022-06-20T23:21:42.477909Z",
     "shell.execute_reply.started": "2022-06-20T22:15:02.509933Z"
    },
    "id": "bJQv4DSelwnB",
    "papermill": {
     "duration": 5.698142,
     "end_time": "2022-06-20T23:21:42.478973",
     "exception": false,
     "start_time": "2022-06-20T23:21:36.780831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import tqdm\n",
    "import spacy\n",
    "import string\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f8b78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:21:42.576142Z",
     "iopub.status.busy": "2022-06-20T23:21:42.575320Z",
     "iopub.status.idle": "2022-06-20T23:21:42.583256Z",
     "shell.execute_reply": "2022-06-20T23:21:42.583679Z",
     "shell.execute_reply.started": "2022-06-20T22:15:07.503172Z"
    },
    "id": "cw16-fZCDHHu",
    "outputId": "b32dc8fa-0126-4a08-8095-3246194aaa90",
    "papermill": {
     "duration": 0.059777,
     "end_time": "2022-06-20T23:21:42.583822",
     "exception": false,
     "start_time": "2022-06-20T23:21:42.524045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 546\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbaedfb",
   "metadata": {
    "id": "xx9pL3Hiyn7c",
    "papermill": {
     "duration": 0.045352,
     "end_time": "2022-06-20T23:21:42.675282",
     "exception": false,
     "start_time": "2022-06-20T23:21:42.629930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare data\n",
    "\n",
    "***Download data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3496530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:21:42.793015Z",
     "iopub.status.busy": "2022-06-20T23:21:42.776342Z",
     "iopub.status.idle": "2022-06-20T23:21:47.606236Z",
     "shell.execute_reply": "2022-06-20T23:21:47.605686Z",
     "shell.execute_reply.started": "2022-06-20T22:15:07.513839Z"
    },
    "id": "kBy3v4Pke7dq",
    "outputId": "91f3948f-e918-44dd-decc-dbf8e23bb890",
    "papermill": {
     "duration": 4.885633,
     "end_time": "2022-06-20T23:21:47.606383",
     "exception": false,
     "start_time": "2022-06-20T23:21:42.720750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf ./data\n",
    "!mkdir ./data\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json \\\n",
    "    -O ./data/train-v1.1.json\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json \\\n",
    "    -O ./data/dev-v1.1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849249e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Dutch SQuAD2.0 dev set\n",
    "!wget -P data/squad/ https://gitlab.com/niels.rouws/dutch-squad-v2.0/-/raw/main/nl_squad_dev_filtered.json\n",
    "\n",
    "# Download the Dutch SQuAD2.0 train set\n",
    "!wget -P data/squad/ https://gitlab.com/niels.rouws/dutch-squad-v2.0/-/raw/main/nl_squad_train_filtered.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9582dca",
   "metadata": {
    "id": "L9H59xUnyvAR",
    "papermill": {
     "duration": 0.0488,
     "end_time": "2022-06-20T23:21:47.703406",
     "exception": false,
     "start_time": "2022-06-20T23:21:47.654606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***Load JSON data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f93b91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:21:47.806976Z",
     "iopub.status.busy": "2022-06-20T23:21:47.805902Z",
     "iopub.status.idle": "2022-06-20T23:21:47.807721Z",
     "shell.execute_reply": "2022-06-20T23:21:47.808135Z",
     "shell.execute_reply.started": "2022-06-20T22:15:10.624200Z"
    },
    "id": "IbZQjhA5roqo",
    "papermill": {
     "duration": 0.05672,
     "end_time": "2022-06-20T23:21:47.808278",
     "exception": false,
     "start_time": "2022-06-20T23:21:47.751558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load(path):\n",
    "    with open(path, mode='r', encoding='utf-8') as file:\n",
    "        return json.load(file)['data']\n",
    "    raise FileNotFoundError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585993d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:21:47.909201Z",
     "iopub.status.busy": "2022-06-20T23:21:47.907430Z",
     "iopub.status.idle": "2022-06-20T23:21:47.935743Z",
     "shell.execute_reply": "2022-06-20T23:21:47.935095Z",
     "shell.execute_reply.started": "2022-06-20T22:15:10.632389Z"
    },
    "papermill": {
     "duration": 0.079961,
     "end_time": "2022-06-20T23:21:47.935899",
     "exception": false,
     "start_time": "2022-06-20T23:21:47.855938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_raw_data = load('./data/squad/nl_squad_train_filtered.json')\n",
    "valid_raw_data = load('./data/squad/nl_squad_dev_filtered.json')\n",
    "print(f'Length of raw train data: {len(train_raw_data):,}')\n",
    "print(f'Length of raw valid data: {len(valid_raw_data):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63708404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:21:48.055474Z",
     "iopub.status.busy": "2022-06-20T23:21:48.054523Z",
     "iopub.status.idle": "2022-06-20T23:21:48.721920Z",
     "shell.execute_reply": "2022-06-20T23:21:48.721466Z",
     "shell.execute_reply.started": "2022-06-20T22:15:10.659003Z"
    },
    "id": "rqjrkTxHr3rA",
    "outputId": "e580a2e1-0fdd-42aa-e2d0-ab809c311bf2",
    "papermill": {
     "duration": 0.735886,
     "end_time": "2022-06-20T23:21:48.722045",
     "exception": false,
     "start_time": "2022-06-20T23:21:47.986159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_raw_data2 = load('./data/train-v1.1.json')\n",
    "valid_raw_data2 = load('./data/dev-v1.1.json')\n",
    "print(f'Length of raw train data: {len(train_raw_data2):,}')\n",
    "print(f'Length of raw valid data: {len(valid_raw_data2):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17432504",
   "metadata": {
    "id": "n4sypWlVyxx-",
    "papermill": {
     "duration": 0.047809,
     "end_time": "2022-06-20T23:21:48.817064",
     "exception": false,
     "start_time": "2022-06-20T23:21:48.769255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***Parse JSON data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec3948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:21:48.935781Z",
     "iopub.status.busy": "2022-06-20T23:21:48.918100Z",
     "iopub.status.idle": "2022-06-20T23:22:03.814791Z",
     "shell.execute_reply": "2022-06-20T23:22:03.813921Z",
     "shell.execute_reply.started": "2022-06-20T22:15:11.352263Z"
    },
    "papermill": {
     "duration": 14.949417,
     "end_time": "2022-06-20T23:22:03.814948",
     "exception": false,
     "start_time": "2022-06-20T23:21:48.865531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm >> /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedeb1f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:22:03.918414Z",
     "iopub.status.busy": "2022-06-20T23:22:03.917608Z",
     "iopub.status.idle": "2022-06-20T23:22:05.079839Z",
     "shell.execute_reply": "2022-06-20T23:22:05.079027Z",
     "shell.execute_reply.started": "2022-06-20T22:15:50.656916Z"
    },
    "papermill": {
     "duration": 1.217459,
     "end_time": "2022-06-20T23:22:05.079985",
     "exception": false,
     "start_time": "2022-06-20T23:22:03.862526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse(data, nlp=spacy.load('en_core_web_sm')):\n",
    "    qas = []\n",
    "    for paragraphs in tqdm.tqdm(data):\n",
    "        for para in paragraphs['paragraphs']:\n",
    "            context = nlp(para['context'], disable=['parser'])\n",
    "            for qa in para['qas']:\n",
    "                id = qa['id']\n",
    "                question = nlp(qa['question'], disable=['parser', 'tagger', 'ner'])\n",
    "                for ans in qa['answers']:\n",
    "                    qas.append({\n",
    "                        'id': id,\n",
    "                        'context': context,\n",
    "                        'question': question,\n",
    "                        'answer': nlp(ans['text'], disable=['parser', 'tagger', 'ner']),\n",
    "                        'answer_start': ans['answer_start'],\n",
    "                    })\n",
    "    return qas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38568394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:22:05.178505Z",
     "iopub.status.busy": "2022-06-20T23:22:05.177691Z",
     "iopub.status.idle": "2022-06-20T23:22:05.929681Z",
     "shell.execute_reply": "2022-06-20T23:22:05.929157Z",
     "shell.execute_reply.started": "2022-06-20T22:15:51.833186Z"
    },
    "id": "O-6GE3YxsQsl",
    "papermill": {
     "duration": 0.80213,
     "end_time": "2022-06-20T23:22:05.929834",
     "exception": false,
     "start_time": "2022-06-20T23:22:05.127704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse(data, nlp=spacy.load('en_core_web_sm')):\n",
    "    qas = []\n",
    "    for paragraphs in tqdm.tqdm(data):\n",
    "        for para in paragraphs['paragraphs']:\n",
    "            context = nlp(para['context'], disable=['parser'])\n",
    "            for qa in para['qas']:\n",
    "                id = qa['id']\n",
    "                question = nlp(qa['question'], disable=['parser', 'tagger', 'ner'])\n",
    "                for ans in qa['answers']:\n",
    "                    qas.append({\n",
    "                        'id': id,\n",
    "                        'context': context,\n",
    "                        'question': question,\n",
    "                        'answer': nlp(ans['text'], disable=['parser', 'tagger', 'ner']),\n",
    "                        'answer_start': ans['answer_start'],\n",
    "                    })\n",
    "    return qas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3789bb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:22:06.034442Z",
     "iopub.status.busy": "2022-06-20T23:22:06.033494Z",
     "iopub.status.idle": "2022-06-20T23:22:19.658074Z",
     "shell.execute_reply": "2022-06-20T23:22:19.657607Z",
     "shell.execute_reply.started": "2022-06-20T22:15:52.577156Z"
    },
    "id": "6MeqBr7Ov9ZU",
    "outputId": "ed78c371-fb36-4969-b669-bdffeb7aa067",
    "papermill": {
     "duration": 13.68017,
     "end_time": "2022-06-20T23:22:19.658198",
     "exception": false,
     "start_time": "2022-06-20T23:22:05.978028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_qas = parse(train_raw_data)\n",
    "valid_qas = parse(valid_raw_data)\n",
    "print()\n",
    "print(f'Length of train qa pairs: {len(train_qas):,}')\n",
    "print(f'Length of valid qa pairs: {len(valid_qas):,}')\n",
    "print('==================== Example ====================')\n",
    "print('Id:', train_qas[0]['id'])\n",
    "print('Context:', train_qas[0]['context'])\n",
    "print('Question:', train_qas[0]['question'])\n",
    "print('Answer starts at:', train_qas[0]['answer_start'])\n",
    "print('Answer:', train_qas[0]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0491396b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:22:19.811872Z",
     "iopub.status.busy": "2022-06-20T23:22:19.811076Z",
     "iopub.status.idle": "2022-06-20T23:22:19.813141Z",
     "shell.execute_reply": "2022-06-20T23:22:19.813543Z",
     "shell.execute_reply.started": "2022-06-20T22:16:05.652446Z"
    },
    "id": "bafKgiFv1GHa",
    "papermill": {
     "duration": 0.081776,
     "end_time": "2022-06-20T23:22:19.813692",
     "exception": false,
     "start_time": "2022-06-20T23:22:19.731916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_answer_start(qas):\n",
    "    \"\"\"Test answer_start are correct in train set\"\"\"\n",
    "    for qa in tqdm.tqdm(qas):\n",
    "        answer = qa['answer'].text\n",
    "        context = qa['context'].text\n",
    "        answer_start = qa['answer_start']\n",
    "        assert answer == context[answer_start:answer_start + len(answer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b10e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T23:22:19.963677Z",
     "iopub.status.busy": "2022-06-20T23:22:19.962788Z",
     "iopub.status.idle": "2022-06-20T23:22:20.409637Z",
     "shell.execute_reply": "2022-06-20T23:22:20.409086Z",
     "shell.execute_reply.started": "2022-06-20T22:16:05.660850Z"
    },
    "id": "3tTDTQod23-g",
    "outputId": "04caed6c-0f1b-49f0-c5a7-3373385c064b",
    "papermill": {
     "duration": 0.523046,
     "end_time": "2022-06-20T23:22:20.409912",
     "exception": true,
     "start_time": "2022-06-20T23:22:19.886866",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_answer_start(train_qas)\n",
    "test_answer_start(valid_qas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2909393",
   "metadata": {
    "id": "pxhCfiNY28zs",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "***Add targets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240d4f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:43.458606Z",
     "iopub.status.busy": "2022-06-20T22:17:43.458169Z",
     "iopub.status.idle": "2022-06-20T22:17:43.475354Z",
     "shell.execute_reply": "2022-06-20T22:17:43.473554Z",
     "shell.execute_reply.started": "2022-06-20T22:17:43.458558Z"
    },
    "id": "k4bpqV3S27SQ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_targets(qas):\n",
    "    \"\"\"Add start and end index token\"\"\"\n",
    "    for qa in qas:\n",
    "        context = qa['context']\n",
    "        answer = qa['answer']\n",
    "        ans_start = qa['answer_start']\n",
    "        for i in range(len(context)):\n",
    "            if context[i].idx == ans_start:\n",
    "                ans = context[i:i + len(answer)]\n",
    "                qa['target'] = [ans[0].i, ans[-1].i]\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d8b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:43.481694Z",
     "iopub.status.busy": "2022-06-20T22:17:43.480340Z",
     "iopub.status.idle": "2022-06-20T22:17:43.511963Z",
     "shell.execute_reply": "2022-06-20T22:17:43.511177Z",
     "shell.execute_reply.started": "2022-06-20T22:17:43.481653Z"
    },
    "id": "waJedA674CCH",
    "outputId": "1105003e-44e8-4220-f819-c1caf2933702",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "add_targets(train_qas)\n",
    "add_targets(valid_qas)\n",
    "print(f'Length of train qa pairs: {len(train_qas):,}')\n",
    "print(f'Length of valid qa pairs: {len(valid_qas):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4d16f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:43.518617Z",
     "iopub.status.busy": "2022-06-20T22:17:43.516724Z",
     "iopub.status.idle": "2022-06-20T22:17:43.525639Z",
     "shell.execute_reply": "2022-06-20T22:17:43.524821Z",
     "shell.execute_reply.started": "2022-06-20T22:17:43.518579Z"
    },
    "id": "lT65eePm4F9w",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_qas(qa):\n",
    "    \"\"\"Remove bad targets\"\"\"\n",
    "    if 'target' in [*qa.keys()]:\n",
    "        start, end = qa['target']\n",
    "        return qa['context'][start:end + 1].text == qa['answer'].text\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ce5d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:43.534146Z",
     "iopub.status.busy": "2022-06-20T22:17:43.531900Z",
     "iopub.status.idle": "2022-06-20T22:17:43.556830Z",
     "shell.execute_reply": "2022-06-20T22:17:43.556035Z",
     "shell.execute_reply.started": "2022-06-20T22:17:43.534108Z"
    },
    "id": "V_nUlM_n4Mgc",
    "outputId": "5ba86b7f-4951-4a33-f20e-afeb8ec25a9f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_qas = [*filter(filter_qas, train_qas)]\n",
    "valid_qas = [*filter(filter_qas, valid_qas)]\n",
    "print(f'Length of train qa pairs after filtering out bad qa pairs: {len(train_qas):,}')\n",
    "print(f'Length of valid qa pairs after filtering out bad qa pairs: {len(valid_qas):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d547c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:43.558953Z",
     "iopub.status.busy": "2022-06-20T22:17:43.558095Z",
     "iopub.status.idle": "2022-06-20T22:17:43.567998Z",
     "shell.execute_reply": "2022-06-20T22:17:43.566935Z",
     "shell.execute_reply.started": "2022-06-20T22:17:43.558914Z"
    },
    "id": "qKEhn4eI4P5B",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_targets(qas):\n",
    "    for qa in qas:\n",
    "        if 'target' in [*qa.keys()]:\n",
    "            start, end = qa['target']\n",
    "            assert qa['context'][start:end + 1].text == qa['answer'].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a9eb26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:43.573515Z",
     "iopub.status.busy": "2022-06-20T22:17:43.572914Z",
     "iopub.status.idle": "2022-06-20T22:17:43.593680Z",
     "shell.execute_reply": "2022-06-20T22:17:43.592889Z",
     "shell.execute_reply.started": "2022-06-20T22:17:43.573479Z"
    },
    "id": "6O_fmDJl5R7V",
    "outputId": "8237b639-d6b9-45b7-809e-36ae7e2a918b",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_targets(train_qas)\n",
    "test_targets(valid_qas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e066c8",
   "metadata": {
    "id": "AkLppZOP5Vju",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "***Add features***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d91aa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:43.595319Z",
     "iopub.status.busy": "2022-06-20T22:17:43.594929Z",
     "iopub.status.idle": "2022-06-20T22:17:43.611613Z",
     "shell.execute_reply": "2022-06-20T22:17:43.610807Z",
     "shell.execute_reply.started": "2022-06-20T22:17:43.595286Z"
    },
    "id": "O8Y038pt5VIc",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_features(qas):\n",
    "    \"\"\"Add extra features: Exact Match, Part-of-Speech, Name Entity Recognition & Normalized Term Frequency\"\"\"\n",
    "    for qa in tqdm.tqdm(qas):\n",
    "        question = [token.text.lower() for token in qa['question']]\n",
    "        context = qa['context']\n",
    "        counts = collections.Counter(map(lambda token: token.text.lower(), context))\n",
    "        freqs = {index: counts[token.text.lower()] for index, token in enumerate(context)}\n",
    "        freqs_norm = sum(freqs.values())\n",
    "        qa['em'], qa['pos'], qa['ner'], qa['ntf'] = zip(\n",
    "            *map(lambda index: [\n",
    "                context[index].text.lower() in question, context[index].tag_,\n",
    "                context[index].ent_type_ or 'None',\n",
    "                freqs[index] / freqs_norm\n",
    "            ], range(len(context)))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdc903a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:43.614967Z",
     "iopub.status.busy": "2022-06-20T22:17:43.613796Z",
     "iopub.status.idle": "2022-06-20T22:17:44.176002Z",
     "shell.execute_reply": "2022-06-20T22:17:44.175070Z",
     "shell.execute_reply.started": "2022-06-20T22:17:43.614923Z"
    },
    "id": "jqwcbDgPSmp8",
    "outputId": "6b504234-9961-478c-90e2-279f183c9be4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "add_features(train_qas)\n",
    "add_features(valid_qas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4e7bda",
   "metadata": {
    "id": "X8SrKXlfoU5y",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "***Build vocabularies***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c69ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:44.179527Z",
     "iopub.status.busy": "2022-06-20T22:17:44.179236Z",
     "iopub.status.idle": "2022-06-20T22:17:44.193258Z",
     "shell.execute_reply": "2022-06-20T22:17:44.192092Z",
     "shell.execute_reply.started": "2022-06-20T22:17:44.179490Z"
    },
    "id": "2LYjZhu7m6YI",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "\n",
    "    def __init__(self, pad_token, unk_token):\n",
    "        self.pad_token = pad_token\n",
    "        self.unk_token = unk_token\n",
    "        self.vocab = None\n",
    "        self.word2count = None\n",
    "        self.word2index = None\n",
    "        self.index2word = None\n",
    "    \n",
    "    def build(self, data, min_freq):\n",
    "        \"\"\"\n",
    "        :param List[Union[spacy.tokens.doc.Doc, str, Tuple]] data\n",
    "        :param int min_freq\n",
    "        \"\"\"\n",
    "        words = [self.pad_token, self.unk_token]\n",
    "        type_0 = type(data[0])\n",
    "        if type_0 == spacy.tokens.doc.Doc:\n",
    "            for item in data: # context and question\n",
    "                words += [word.text.lower() for word in item]\n",
    "        elif type_0 == str: # id\n",
    "            words += data\n",
    "        elif type_0 == tuple: # pos and ner\n",
    "            for item in data:\n",
    "                words += [word.lower() for word in item]\n",
    "        self.word2count = collections.Counter(words)\n",
    "        self.vocab = sorted(filter(\n",
    "            lambda word: self.word2count[word] >= min_freq or word == self.pad_token or word == self.unk_token, self.word2count\n",
    "        ))\n",
    "        self.word2index = {word: index for index, word in enumerate(self.vocab)}\n",
    "        self.index2word = {index: word for index, word in enumerate(self.vocab)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.vocab)\n",
    "    \n",
    "    def stoi(self, word):\n",
    "        return self.word2index.get(str(word), self.word2index[self.unk_token])\n",
    "\n",
    "    def itos(self, index):\n",
    "        return self.index2word[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8030d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:44.195650Z",
     "iopub.status.busy": "2022-06-20T22:17:44.194841Z",
     "iopub.status.idle": "2022-06-20T22:17:44.310092Z",
     "shell.execute_reply": "2022-06-20T22:17:44.309183Z",
     "shell.execute_reply.started": "2022-06-20T22:17:44.195551Z"
    },
    "id": "C2RP28pUqYoQ",
    "outputId": "12a0af28-0593-45b6-e836-01e9706fd68b",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "PAD_TOKEN = '<pad>'\n",
    "UNK_TOKEN = '<unk>'\n",
    "\n",
    "ID = Vocab(pad_token=PAD_TOKEN, unk_token=UNK_TOKEN)\n",
    "POS = Vocab(pad_token=PAD_TOKEN, unk_token=UNK_TOKEN)\n",
    "NER = Vocab(pad_token=PAD_TOKEN, unk_token=UNK_TOKEN)\n",
    "TEXT = Vocab(pad_token=PAD_TOKEN, unk_token=UNK_TOKEN)\n",
    "\n",
    "ids = [*map(lambda qa: qa['id'], train_qas)] + [*map(lambda qa: qa['id'], valid_qas)]\n",
    "pos, ner, contexts, questions = zip(*map(lambda qa: (qa['pos'], qa['ner'], qa['context'], qa['question']), train_qas))\n",
    "\n",
    "ID.build(data=[*set(ids)], min_freq=0)\n",
    "POS.build(data=[*set(pos)], min_freq=0)\n",
    "NER.build(data=[*set(ner)], min_freq=0)\n",
    "TEXT.build(data=[*set(contexts)] + [*set(questions)], min_freq=5)\n",
    "\n",
    "print(f'Length of ID vocabulary: {len(ID):,}')\n",
    "print(f'Length of POS vocabulary: {len(POS):,}')\n",
    "print(f'Length of NER vocabulary: {len(NER):,}')\n",
    "print(f'Length of TEXT vocabulary: {len(TEXT):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90734e1a",
   "metadata": {
    "id": "t26xjG9OAikb",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "***Build datasets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a57608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:44.312059Z",
     "iopub.status.busy": "2022-06-20T22:17:44.311534Z",
     "iopub.status.idle": "2022-06-20T22:17:44.323716Z",
     "shell.execute_reply": "2022-06-20T22:17:44.322814Z",
     "shell.execute_reply.started": "2022-06-20T22:17:44.312018Z"
    },
    "id": "iotg02zlAflQ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SQuADV1Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, id_vocab, pos_vocab, ner_vocab, text_vocab):\n",
    "        self.data = data\n",
    "        self.id_vocab = id_vocab\n",
    "        self.pos_vocab = pos_vocab\n",
    "        self.ner_vocab = ner_vocab\n",
    "        self.text_vocab = text_vocab\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        id = torch.LongTensor([self.id_vocab.stoi(item['id'])])\n",
    "        ctx = torch.LongTensor([*map(lambda token: self.text_vocab.stoi(token.text.lower()), item['context'])])\n",
    "        qst = torch.LongTensor([*map(lambda token: self.text_vocab.stoi(token.text.lower()), item['question'])])\n",
    "        trg = torch.LongTensor(item['target'])\n",
    "        em = torch.LongTensor(item['em'])\n",
    "        pos = torch.LongTensor([*map(lambda token: self.pos_vocab.stoi(token.lower()), item['pos'])])\n",
    "        ner = torch.LongTensor([*map(lambda token: self.ner_vocab.stoi(token.lower()), item['ner'])])\n",
    "        ntf = torch.FloatTensor(item['ntf'])\n",
    "        return id, ctx, qst, trg, em, pos, ner, ntf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02305e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:44.325438Z",
     "iopub.status.busy": "2022-06-20T22:17:44.325162Z",
     "iopub.status.idle": "2022-06-20T22:17:44.344187Z",
     "shell.execute_reply": "2022-06-20T22:17:44.343392Z",
     "shell.execute_reply.started": "2022-06-20T22:17:44.325394Z"
    },
    "id": "XMgSisEt8ARe",
    "outputId": "72e677f3-c6d7-4df1-eb1d-b24a45181e05",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = SQuADV1Dataset(data=train_qas, id_vocab=ID, pos_vocab=POS, ner_vocab=NER, text_vocab=TEXT)\n",
    "valid_dataset = SQuADV1Dataset(data=valid_qas, id_vocab=ID, pos_vocab=POS, ner_vocab=NER, text_vocab=TEXT)\n",
    "\n",
    "id, ctx, qst, trg, em, pos, ner, ntf = train_dataset[0]\n",
    "print(f'id shape: {id.shape}')\n",
    "print(f'ctx shape: {ctx.shape}')\n",
    "print(f'qst shape: {qst.shape}')\n",
    "print(f'trg shape: {trg.shape}')\n",
    "print(f'em shape: {em.shape}')\n",
    "print(f'pos shape: {pos.shape}')\n",
    "print(f'ner shape: {ner.shape}')\n",
    "print(f'ntf shape: {ntf.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79761226",
   "metadata": {
    "id": "3ZQaVaHt_MDc",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "***Build data loaders***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d0083",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:44.348210Z",
     "iopub.status.busy": "2022-06-20T22:17:44.345458Z",
     "iopub.status.idle": "2022-06-20T22:17:44.352582Z",
     "shell.execute_reply": "2022-06-20T22:17:44.351443Z",
     "shell.execute_reply.started": "2022-06-20T22:17:44.348094Z"
    },
    "id": "PPKrJOpKTlN1",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DotDict(dict):\n",
    "    __getattr__ = dict.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb962283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:44.354556Z",
     "iopub.status.busy": "2022-06-20T22:17:44.354185Z",
     "iopub.status.idle": "2022-06-20T22:17:44.369195Z",
     "shell.execute_reply": "2022-06-20T22:17:44.368421Z",
     "shell.execute_reply.started": "2022-06-20T22:17:44.354493Z"
    },
    "id": "cYMYz3-SBYzf",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_padding(batch, pad_token=PAD_TOKEN, text_vocab=TEXT, pos_vocab=POS, ner_vocab=NER, include_lengths=True, device=DEVICE):\n",
    "    \"\"\"Pad batch of sequence with different lengths\"\"\"\n",
    "    batch_id, batch_ctx, batch_qst, batch_trg, batch_em, batch_pos, batch_ner, batch_ntf = zip(*batch)\n",
    "    if include_lengths:\n",
    "        len_ctx = torch.LongTensor([ctx.size(0) for ctx in batch_ctx]).to(device)\n",
    "        len_qst = torch.LongTensor([qst.size(0) for qst in batch_qst]).to(device)\n",
    "    batch_padded_id = pad_sequence(batch_id, batch_first=True).to(device)\n",
    "    batch_padded_ctx = pad_sequence(batch_ctx, batch_first=True, padding_value=text_vocab.stoi(pad_token)).to(device)\n",
    "    batch_padded_qst = pad_sequence(batch_qst, batch_first=True, padding_value=text_vocab.stoi(pad_token)).to(device)\n",
    "    batch_padded_trg = pad_sequence(batch_trg, batch_first=True).to(device)\n",
    "    batch_padded_em = pad_sequence(batch_em, batch_first=True).to(device)\n",
    "    batch_padded_pos = pad_sequence(batch_pos, batch_first=True, padding_value=pos_vocab.stoi(pad_token)).to(device)\n",
    "    batch_padded_ner = pad_sequence(batch_ner, batch_first=True, padding_value=ner_vocab.stoi(pad_token)).to(device)\n",
    "    batch_padded_ntf = pad_sequence(batch_ntf, batch_first=True).to(device)\n",
    "    return DotDict({\n",
    "        'id': batch_padded_id,\n",
    "        'ctx': (batch_padded_ctx, len_ctx) if include_lengths else batch_padded_ctx,\n",
    "        'qst': (batch_padded_qst, len_qst) if include_lengths else batch_padded_qst,\n",
    "        'trg': batch_padded_trg,\n",
    "        'em': batch_padded_em,\n",
    "        'pos': batch_padded_pos,\n",
    "        'ner': batch_padded_ner,\n",
    "        'ntf': batch_padded_ntf,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b548e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:44.371759Z",
     "iopub.status.busy": "2022-06-20T22:17:44.371060Z",
     "iopub.status.idle": "2022-06-20T22:17:49.914948Z",
     "shell.execute_reply": "2022-06-20T22:17:49.914139Z",
     "shell.execute_reply.started": "2022-06-20T22:17:44.371722Z"
    },
    "id": "Zu2ovPqxA7Ix",
    "outputId": "6e6fdd4b-ba3f-4a9b-fa50-dc5ed492f2e2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=add_padding)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=add_padding)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    print('batch.id shape:', batch.id.shape)\n",
    "    print('batch.ctx shape:', batch.ctx[0].shape, batch.ctx[1].shape)\n",
    "    print('batch.qst shape:', batch.qst[0].shape, batch.qst[1].shape)\n",
    "    print('batch.trg shape:', batch.trg.shape)\n",
    "    print('batch.em shape:', batch.em.shape)\n",
    "    print('batch.pos shape:', batch.pos.shape)\n",
    "    print('batch.ner shape:', batch.ner.shape)\n",
    "    print('batch.ntf shape:', batch.ntf.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a712d",
   "metadata": {
    "id": "z2O79r_CLvGu",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "***Download pretrained GloVe embedding***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018cf18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:17:49.918238Z",
     "iopub.status.busy": "2022-06-20T22:17:49.918035Z",
     "iopub.status.idle": "2022-06-20T22:25:46.040183Z",
     "shell.execute_reply": "2022-06-20T22:25:46.038922Z",
     "shell.execute_reply.started": "2022-06-20T22:17:49.918213Z"
    },
    "id": "hrSXYalOmRak",
    "outputId": "504c609a-65ca-4f5e-9bb6-8d1ffcbf87c6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!wget --no-check-certificate \\\n",
    "    http://nlp.stanford.edu/data/glove.840B.300d.zip \\\n",
    "    -O ./data/glove.840B.300d.zip\n",
    "!unzip -q ./data/glove.840B.300d.zip -d ./data\n",
    "!rm -r ./data/glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d441c1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:25:46.042650Z",
     "iopub.status.busy": "2022-06-20T22:25:46.042250Z",
     "iopub.status.idle": "2022-06-20T22:25:46.050682Z",
     "shell.execute_reply": "2022-06-20T22:25:46.049794Z",
     "shell.execute_reply.started": "2022-06-20T22:25:46.042603Z"
    },
    "id": "BL0JZuEmmf5C",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_glove(path):\n",
    "    glove = {}\n",
    "    with open(path, mode='r', encoding='utf-8') as file:\n",
    "        for line in tqdm.tqdm(file):\n",
    "            values = line.split(' ')\n",
    "            glove[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "        return glove\n",
    "    raise FileNotFoundError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf5fe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:25:46.052733Z",
     "iopub.status.busy": "2022-06-20T22:25:46.052148Z",
     "iopub.status.idle": "2022-06-20T22:30:07.884249Z",
     "shell.execute_reply": "2022-06-20T22:30:07.883506Z",
     "shell.execute_reply.started": "2022-06-20T22:25:46.052697Z"
    },
    "id": "BDX8b2EJm1uZ",
    "outputId": "94d33380-f5f3-4450-be42-3be8a20098f8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "glove = load_glove(path='./data/glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82698a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:30:07.891094Z",
     "iopub.status.busy": "2022-06-20T22:30:07.890656Z",
     "iopub.status.idle": "2022-06-20T22:30:07.899810Z",
     "shell.execute_reply": "2022-06-20T22:30:07.899154Z",
     "shell.execute_reply.started": "2022-06-20T22:30:07.891063Z"
    },
    "id": "ELVYepbbm7ny",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_embeddings(glove, text_vocab, embedding_size=300, most_common=1000):\n",
    "    most_common_words = [*map(lambda x: x[0], text_vocab.word2count.most_common(most_common))]\n",
    "    most_common_words = [*filter(lambda word: word in text_vocab.vocab, most_common_words)]\n",
    "    embedding_matrix = np.zeros((len(text_vocab), embedding_size))\n",
    "    most_common_indexes, n_words = [], 0\n",
    "    for index, word in enumerate(text_vocab.vocab):\n",
    "        if word in most_common_words:\n",
    "            most_common_indexes.append(index)\n",
    "        try:\n",
    "            embedding_matrix[index] = glove[word]\n",
    "            n_words += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return embedding_matrix, n_words, most_common_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1e800b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:30:07.903174Z",
     "iopub.status.busy": "2022-06-20T22:30:07.902826Z",
     "iopub.status.idle": "2022-06-20T22:30:07.946764Z",
     "shell.execute_reply": "2022-06-20T22:30:07.946058Z",
     "shell.execute_reply.started": "2022-06-20T22:30:07.903146Z"
    },
    "id": "3CUDosl_n5HA",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_matrix, n_words, most_common_indexes = load_embeddings(glove, text_vocab=TEXT)\n",
    "print(f'Words found: {n_words}/{len(TEXT)}')\n",
    "np.save('./data/GloVe_DrQA.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2096455b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:30:07.948723Z",
     "iopub.status.busy": "2022-06-20T22:30:07.948143Z",
     "iopub.status.idle": "2022-06-20T22:30:08.730565Z",
     "shell.execute_reply": "2022-06-20T22:30:08.729750Z",
     "shell.execute_reply.started": "2022-06-20T22:30:07.948680Z"
    },
    "id": "JZzbAOFAmfnT",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Free up the RAM\n",
    "del glove\n",
    "del embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a15bf1",
   "metadata": {
    "id": "bxnYdks-L31E",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Modeling\n",
    "\n",
    "***Stacked Bidirectional LSTM Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636fc865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:36:31.299479Z",
     "iopub.status.busy": "2022-06-20T22:36:31.299117Z",
     "iopub.status.idle": "2022-06-20T22:36:31.317159Z",
     "shell.execute_reply": "2022-06-20T22:36:31.316317Z",
     "shell.execute_reply.started": "2022-06-20T22:36:31.299437Z"
    },
    "id": "DoHYvqQQCEGw",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StackedBiLSTMsLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, hidden_size, n_layers, dropout):\n",
    "        super(StackedBiLSTMsLayer, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstms = nn.ModuleList([nn.LSTM(embedding_size if i == 0 else hidden_size * 2, hidden_size,\n",
    "                                            batch_first=True, num_layers=n_layers, bidirectional=True)\n",
    "                                    for i in range(n_layers)])\n",
    "    \n",
    "    def apply_lstm(self, layer, inputs, lengths):\n",
    "        \"\"\"\n",
    "        :param nn.LSTM layer\n",
    "        :param FloatTensor[batch_size, seq_len, embedding_size | hidden_size * 2] inputs\n",
    "        :param LongTensor[batch_size, seq_len] lengths\n",
    "        :return FloatTensor[batch_size, seq_len, hidden_size * 2] out_padded\n",
    "        \"\"\"\n",
    "        inputs = self.dropout(inputs)\n",
    "        packed = pack_padded_sequence(inputs, lengths, batch_first=True, enforce_sorted=False)\n",
    "        out_packed, _ = layer(packed)\n",
    "        out_padded, out_lengths = pad_packed_sequence(out_packed, batch_first=True) # [batch_size, seq_len, hidden_size * 2]\n",
    "        return out_padded, out_lengths\n",
    "    \n",
    "    def forward(self, input_embedded, sequence_lengths):\n",
    "        \"\"\"\n",
    "        :param FloatTensor[batch_size, seq_len, embedding_size] input_embedded\n",
    "        :param LongTensor[batch_size, seq_len] sequence_lengths\n",
    "        :return FloatTensor[batch_size, seq_len, hidden_size * n_layers * 2]\n",
    "        \"\"\"\n",
    "        outputs, lens = [input_embedded], sequence_lengths.cpu()\n",
    "        for lstm in self.lstms:\n",
    "            out, lens = self.apply_lstm(layer=lstm, inputs=outputs[-1], lengths=lens)\n",
    "            outputs.append(out)\n",
    "        return self.dropout(torch.cat(outputs[1:], dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11bd9d4",
   "metadata": {
    "id": "5oazq30eW3_T",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "***Aligned Question Embedding Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb76aef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:36:31.328540Z",
     "iopub.status.busy": "2022-06-20T22:36:31.325537Z",
     "iopub.status.idle": "2022-06-20T22:36:31.341286Z",
     "shell.execute_reply": "2022-06-20T22:36:31.340321Z",
     "shell.execute_reply.started": "2022-06-20T22:36:31.328498Z"
    },
    "id": "ATOQC6-pWzq_",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AlignQuestionEmbeddingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size):\n",
    "        super(AlignQuestionEmbeddingLayer, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, ctx_embed, qst_embed, qst_mask):\n",
    "        \"\"\"\n",
    "        :param FloatTensor[batch_size, ctx_len, embedding_size] ctx_embed\n",
    "        :param FloatTensor[batch_size, qst_len, embedding_size] qst_embed\n",
    "        :param IntTensor[batch_size, qst_len] qst_mask\n",
    "        :return FloatTensor[batch_size, ctx_len, hidden_size]\n",
    "        \"\"\"\n",
    "        ctx_embed = F.relu(self.linear(ctx_embed)) # [batch_size, ctx_len, hidden_size]\n",
    "        qst_embed = F.relu(self.linear(qst_embed)) # [batch_size, qst_len, hidden_size]\n",
    "        scores = torch.bmm(ctx_embed, qst_embed.transpose(-1, -2)) # [batch_size, ctx_len, qst_len]\n",
    "        scores = scores.masked_fill(qst_mask.unsqueeze(1) == 0, 1e-18)\n",
    "        attention_weights = F.softmax(scores, dim=-1) # [batch_size, ctx_len, qst_len]\n",
    "        return torch.bmm(attention_weights, qst_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80771d",
   "metadata": {
    "id": "ImX8ayztYjsK",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "***Question Encoding Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2a57e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:36:31.343548Z",
     "iopub.status.busy": "2022-06-20T22:36:31.343258Z",
     "iopub.status.idle": "2022-06-20T22:36:31.357534Z",
     "shell.execute_reply": "2022-06-20T22:36:31.356815Z",
     "shell.execute_reply.started": "2022-06-20T22:36:31.343511Z"
    },
    "id": "Whil-FgVYhgy",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QuestionEncodingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, hidden_size, dropout, n_layers):\n",
    "        super(QuestionEncodingLayer, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.stacked_bilstms_layer = StackedBiLSTMsLayer(embedding_size=embedding_size, hidden_size=hidden_size, n_layers=n_layers, dropout=dropout)\n",
    "        self.linear = nn.Linear(embedding_size, 1)\n",
    "    \n",
    "    def linear_self_attention(self, qst_embed, qst_mask):\n",
    "        \"\"\"\n",
    "        :param FloatTensor[batch_size, qst_len, embedding_size] qst_embed\n",
    "        :param IntTensor[batch_size, qst_len] qst_mask\n",
    "        :return FloatTensor[batch_size, qst_len]\n",
    "        \"\"\"\n",
    "        scores = self.linear(qst_embed).squeeze(-1) # [batch_size, qst_len]\n",
    "        scores = scores.masked_fill(qst_mask == 0, 1e-18)\n",
    "        return F.softmax(scores, dim=-1)\n",
    "    \n",
    "    def forward(self, qst_embed, qst_lengths, qst_mask):\n",
    "        \"\"\"\n",
    "        :param FloatTensor[batch_size, qst_len, embedding_size] qst_embed\n",
    "        :param IntTensor[batch_size, qst_len] qst_lengths\n",
    "        :param IntTensor[batch_size, qst_len] qst_mask\n",
    "        :return FloatTensor[batch_size, hidden_size * n_layers * 2]\n",
    "        \"\"\"\n",
    "        attention_weights = self.linear_self_attention(qst_embed=qst_embed, qst_mask=qst_mask) # [batch_size, qst_len]\n",
    "        lstm_outputs = self.stacked_bilstms_layer(input_embedded=qst_embed, sequence_lengths=qst_lengths)\n",
    "        # lstm_outputs: [batch_size, qst_len, hidden_size * n_layers * 2]\n",
    "        return torch.bmm(attention_weights.unsqueeze(1), lstm_outputs).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5081f1af",
   "metadata": {
    "id": "4hFIZnmUaFAu",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "***BiLinear Attention Layer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab3cee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:36:31.359615Z",
     "iopub.status.busy": "2022-06-20T22:36:31.359208Z",
     "iopub.status.idle": "2022-06-20T22:36:31.378824Z",
     "shell.execute_reply": "2022-06-20T22:36:31.377726Z",
     "shell.execute_reply.started": "2022-06-20T22:36:31.359581Z"
    },
    "id": "JZGOH3IhaEZw",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiLinearAttentionLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, ctx_size, qst_size):\n",
    "        super(BiLinearAttentionLayer, self).__init__()\n",
    "        self.ctx_size = ctx_size\n",
    "        self.qst_size = qst_size\n",
    "        self.linear = nn.Linear(qst_size, ctx_size)\n",
    "    \n",
    "    def forward(self, ctx_encoded, qst_encoded, ctx_mask):\n",
    "        \"\"\"\n",
    "        :param FloatTensor[batch_size, ctx_len, ctx_size] ctx_encoded\n",
    "        :param FloatTensor[batch_size, qst_size] qst_encoded\n",
    "        :param IntTensor[batch_size, ctx_len] ctx_mask\n",
    "        :return FloatTensor[batch_size, ctx_len, hidden_size]\n",
    "        \"\"\"\n",
    "        qst_encoded = self.linear(qst_encoded) # [batch_size, ctx_size]\n",
    "        scores = torch.bmm(ctx_encoded, qst_encoded.unsqueeze(-1)) # [batch_size, ctx_len, 1]\n",
    "        scores = scores.squeeze(-1).masked_fill(ctx_mask == 0, 1e-18) # [batch_size, ctx_len]\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d6ac2c",
   "metadata": {
    "id": "tzrmk6D7agHH",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "***Document reader Question Answering Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d502ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:36:31.434450Z",
     "iopub.status.busy": "2022-06-20T22:36:31.433791Z",
     "iopub.status.idle": "2022-06-20T22:36:31.476670Z",
     "shell.execute_reply": "2022-06-20T22:36:31.475361Z",
     "shell.execute_reply.started": "2022-06-20T22:36:31.434405Z"
    },
    "id": "qlZlTFXOae_o",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DrQA(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_size, n_extra_features, hidden_size, n_layers, dropout, pad_index):\n",
    "        super(DrQA, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.n_extra_features = n_extra_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.pad_index = pad_index\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=pad_index)\n",
    "        self.align_question_embedding_layer = AlignQuestionEmbeddingLayer(hidden_size=embedding_size)\n",
    "        self.ctx_stacked_bi_lstm_layer = StackedBiLSTMsLayer(embedding_size=embedding_size * 2 + n_extra_features,\n",
    "                                                             hidden_size=hidden_size, n_layers=n_layers, dropout=dropout)\n",
    "        self.qst_encoding_layer = QuestionEncodingLayer(embedding_size=embedding_size, hidden_size=hidden_size, dropout=dropout, n_layers=n_layers)\n",
    "        self.bilinear_attention_layer_start = BiLinearAttentionLayer(ctx_size=hidden_size * n_layers * 2, qst_size=hidden_size * n_layers * 2)\n",
    "        self.bilinear_attention_layer_end = BiLinearAttentionLayer(ctx_size=hidden_size * n_layers * 2, qst_size=hidden_size * n_layers * 2)\n",
    "    \n",
    "    def load_glove_embeddings(self, path, most_common_indexes, tune=True):\n",
    "        def tune_embeddings(grad, words=most_common_indexes):\n",
    "            grad[most_common_indexes] = 0\n",
    "            return grad\n",
    "        \n",
    "        self.embedding.weight = nn.Parameter(torch.FloatTensor(np.load(path)))\n",
    "        if tune:\n",
    "            self.embedding.weight.register_hook(tune_embeddings) # Only fine-tune the 1000 most frequent question words\\n\n",
    "    \n",
    "    def make_ctx_mask(self, ctx_sequences):\n",
    "        \"\"\"\n",
    "        :param LongTensor[batch_size, ctx_len] ctx_sequences\n",
    "        :return IntTensor[batch_size, ctx_len]\n",
    "        \"\"\"\n",
    "        return ctx_sequences != self.pad_index\n",
    "    \n",
    "    def make_qst_mask(self, qst_sequences):\n",
    "        \"\"\"\n",
    "        :param LongTensor[batch_size, qst_len] qst_sequences\n",
    "        :return IntTensor[batch_size, qst_len]\n",
    "        \"\"\"\n",
    "        return qst_sequences != self.pad_index\n",
    "    \n",
    "    @staticmethod\n",
    "    def decode(starts, ends):\n",
    "        \"\"\"\n",
    "        :param IntTensor[batch_size, ctx_len] starts\n",
    "        :param IntTensor[batch_size, ctx_len] ends\n",
    "        :return list(int) start_indexes\n",
    "        :return list(int) end_indexes\n",
    "        :return list(float) pred_probas\n",
    "        \"\"\"\n",
    "        start_indexes, end_indexes, pred_probas = [], [], []\n",
    "        for i in range(starts.size(0)):\n",
    "            probas = torch.ger(starts[i], ends[i]) # [ctx_len, ctx_len]\n",
    "            proba, index = torch.topk(probas.view(-1), k=1)\n",
    "            start_indexes.append(index.tolist()[0] // probas.size(0))\n",
    "            end_indexes.append(index.tolist()[0] % probas.size(1))\n",
    "            pred_probas.append(proba.tolist()[0])\n",
    "        return start_indexes, end_indexes, pred_probas\n",
    "    \n",
    "    def forward(self, ctx_sequences, ctx_lengths, qst_sequences, qst_lengths, em_sequences, pos_sequences, ner_sequences, ntf_sequences):\n",
    "        \"\"\"\n",
    "        :param LongTensor[batch_size, ctx_len] ctx_sequences\n",
    "        :param Tensor[batch_size,] ctx_lengths\n",
    "        :param LongTensor[batch_size, qst_len] qst_sequences\n",
    "        :param Tensor[batch_size,] qst_lengths\n",
    "        :param LongTensor[batch_size, ctx_len] em_sequences\n",
    "        :param LongTensor[batch_size, ctx_len] pos_sequences\n",
    "        :param LongTensor[batch_size, ctx_len] ner_sequences\n",
    "        :param LongTensor[batch_size, ctx_len] ntf_sequences\n",
    "        :return Tensor[batch_size, ctx_len] starts\n",
    "        :return Tensor[batch_size, ctx_len] ends\n",
    "        \"\"\"\n",
    "        ctx_mask = self.make_ctx_mask(ctx_sequences) # [batch_size, ctx_len]\n",
    "        qst_mask = self.make_qst_mask(qst_sequences) # [batch_size, qst_len]\n",
    "        ctx_embedded = self.dropout(self.embedding(ctx_sequences)) # [batch_size, ctx_len, embedding_size]\n",
    "        qst_embedded = self.dropout(self.embedding(qst_sequences)) # [batch_size, ctx_len, embedding_size]\n",
    "        ctx_aligned = self.align_question_embedding_layer(ctx_embed=ctx_embedded, qst_embed=qst_embedded,\n",
    "                                                          qst_mask=qst_mask) # [batch_size, ctx_len, embedding_size]\n",
    "        ctx_inputs = torch.cat([ctx_embedded, em_sequences.unsqueeze(-1), pos_sequences.unsqueeze(-1), ner_sequences.unsqueeze(-1),\n",
    "                                ntf_sequences.unsqueeze(-1), ctx_aligned], dim=-1) # [batch_size, ctx_len, embedding_size * 2 + 4]\n",
    "        ctx_encoded = self.ctx_stacked_bi_lstm_layer(input_embedded=ctx_inputs, sequence_lengths=ctx_lengths)\n",
    "        # ctx_encoded: [batch_size, ctx_len, hidden_size * n_layers * 2]\n",
    "        qst_encoded = self.qst_encoding_layer(qst_embed=qst_embedded, qst_lengths=qst_lengths, qst_mask=qst_mask)\n",
    "        # qst_encoded: [batch_size, hidden_size * n_layers * 2]\n",
    "        starts = self.bilinear_attention_layer_start(ctx_encoded=ctx_encoded, qst_encoded=qst_encoded, ctx_mask=ctx_mask)\n",
    "        ends = self.bilinear_attention_layer_end(ctx_encoded=ctx_encoded, qst_encoded=qst_encoded, ctx_mask=ctx_mask)\n",
    "        return starts, ends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169d2b5a",
   "metadata": {
    "id": "x575iXlz3w4m",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "***Training routines***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9ea28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:36:31.486260Z",
     "iopub.status.busy": "2022-06-20T22:36:31.484156Z",
     "iopub.status.idle": "2022-06-20T22:36:31.497272Z",
     "shell.execute_reply": "2022-06-20T22:36:31.496250Z",
     "shell.execute_reply.started": "2022-06-20T22:36:31.486212Z"
    },
    "id": "31k5BZf43uV4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.value = 0.\n",
    "        self.sum = 0.\n",
    "        self.count = 0\n",
    "        self.average = 0.\n",
    "        \n",
    "    def reset(self):\n",
    "        self.value = 0.\n",
    "        self.sum = 0.\n",
    "        self.count = 0\n",
    "        self.average = 0.\n",
    "        \n",
    "    def update(self, value, n=1):\n",
    "        self.value = value\n",
    "        self.sum += value * n\n",
    "        self.count += n\n",
    "        self.average = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f223cd45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:36:31.505432Z",
     "iopub.status.busy": "2022-06-20T22:36:31.502694Z",
     "iopub.status.idle": "2022-06-20T22:36:31.515896Z",
     "shell.execute_reply": "2022-06-20T22:36:31.515208Z",
     "shell.execute_reply.started": "2022-06-20T22:36:31.505391Z"
    },
    "id": "qSmh2GmU4KXH",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(answer: str):\n",
    "    \"\"\"Performs a series of cleaning steps on the ground truth and predicted answer.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        return ''.join(ch for ch in text if ch not in set(string.punctuation))\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(answer))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ffdcb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:36:31.524067Z",
     "iopub.status.busy": "2022-06-20T22:36:31.521881Z",
     "iopub.status.idle": "2022-06-20T22:36:31.533601Z",
     "shell.execute_reply": "2022-06-20T22:36:31.532713Z",
     "shell.execute_reply.started": "2022-06-20T22:36:31.524026Z"
    },
    "id": "hi2JHYTX6F6A",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_scores(prediction: str, ground_truth: str):\n",
    "    prediction, ground_truth = normalize(prediction), normalize(ground_truth)\n",
    "    em_score = prediction == ground_truth\n",
    "\n",
    "    prediction_tokens, ground_truth_tokens = prediction.split(), ground_truth.split()\n",
    "    common = collections.Counter(prediction_tokens) & collections.Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        f1_score = 0\n",
    "    else:\n",
    "        precision = 1.0 * num_same / len(prediction_tokens)\n",
    "        recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "        f1_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    return em_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f29aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:36:31.540814Z",
     "iopub.status.busy": "2022-06-20T22:36:31.538266Z",
     "iopub.status.idle": "2022-06-20T22:36:31.549076Z",
     "shell.execute_reply": "2022-06-20T22:36:31.548164Z",
     "shell.execute_reply.started": "2022-06-20T22:36:31.540773Z"
    },
    "id": "tv9kxaI34_Oo",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def max_metrics_over_ground_truths(prediction: str, ground_truths: list):\n",
    "    scores = [get_scores(prediction, ground_truth) for ground_truth in ground_truths]\n",
    "    em_score = max(scores, key=lambda score: score[0])[0]\n",
    "    f1_score = max(scores, key=lambda score: score[1])[1]\n",
    "    return em_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384b84a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:36:31.555755Z",
     "iopub.status.busy": "2022-06-20T22:36:31.553587Z",
     "iopub.status.idle": "2022-06-20T22:36:31.565453Z",
     "shell.execute_reply": "2022-06-20T22:36:31.564611Z",
     "shell.execute_reply.started": "2022-06-20T22:36:31.555719Z"
    },
    "id": "KmxMG01B5JEx",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metrics(predictions: dict, qas=valid_qas):\n",
    "    ground_truths = collections.defaultdict(lambda: [])\n",
    "    for qa in qas:\n",
    "        if qa['id'] in predictions:\n",
    "            ground_truths[qa['id']].append(qa['answer'].text)\n",
    "\n",
    "    em_scores, f1_scores, total = [], [], 0\n",
    "    for id in predictions:\n",
    "        em_score, f1_score = max_metrics_over_ground_truths(predictions[id], ground_truths[id])\n",
    "        em_scores.append(em_score); f1_scores.append(f1_score)\n",
    "        total += 1\n",
    "\n",
    "    em_score = 100.0 * sum(em_scores) / total\n",
    "    f1_score = 100.0 * sum(f1_scores) / total\n",
    "    return em_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb8e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:36:31.572615Z",
     "iopub.status.busy": "2022-06-20T22:36:31.570213Z",
     "iopub.status.idle": "2022-06-20T22:36:31.600502Z",
     "shell.execute_reply": "2022-06-20T22:36:31.599821Z",
     "shell.execute_reply.started": "2022-06-20T22:36:31.572572Z"
    },
    "id": "GHUdYB6f-NRJ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, model, optimizer, criterion, id_field, text_field):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.id_field = id_field\n",
    "        self.text_field = text_field\n",
    "        \n",
    "    def train_step(self, loader, epoch, grad_clip):\n",
    "        loss_tracker = AverageMeter()\n",
    "        self.model.train()\n",
    "        progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "        for i, batch in progress_bar:\n",
    "            self.optimizer.zero_grad()\n",
    "            starts, ends = self.model(*batch.ctx, *batch.qst, batch.em, batch.pos, batch.ner, batch.ntf) # [batch_size, ctx_len]\n",
    "            loss = self.criterion(starts, batch.trg[:, 0]) + self.criterion(ends, batch.trg[:, 1])\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(self.model.parameters(), grad_clip)\n",
    "            self.optimizer.step()\n",
    "            loss_tracker.update(loss.item())\n",
    "            progress_bar.set_description(f'Epoch: {epoch+1:02d} -     loss: {loss_tracker.average:.3f}')\n",
    "        return loss_tracker.average\n",
    "    \n",
    "    def validate(self, loader, epoch):\n",
    "        loss_tracker, predictions = AverageMeter(), {}\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "            for i, batch in progress_bar:\n",
    "                starts, ends = self.model(*batch.ctx, *batch.qst, batch.em, batch.pos, batch.ner, batch.ntf) # [batch_size, ctx_len]\n",
    "                loss = self.criterion(starts, batch.trg[:, 0]) + self.criterion(ends, batch.trg[:, 1])\n",
    "                start_indexes, end_indexes, _ = DrQA.decode(starts=F.softmax(starts, dim=-1), ends=F.softmax(ends, dim=-1))\n",
    "                for i in range(starts.size(0)):\n",
    "                    id = self.id_field.itos(batch.id[i].item())\n",
    "                    prediction = batch.ctx[0][i][start_indexes[i]:end_indexes[i]+1]\n",
    "                    predictions[id] = ' '.join([self.text_field.itos(indice.item()) for indice in prediction])\n",
    "                loss_tracker.update(loss.item())\n",
    "                progress_bar.set_description(f'Epoch: {epoch+1:02d} - val_loss: {loss_tracker.average:.3f}')\n",
    "        return loss_tracker.average, predictions\n",
    "    \n",
    "    def train(self, train_loader, valid_loader, n_epochs, grad_clip):\n",
    "        history, best_loss = {'loss': [], 'val_loss': [], 'em': [], 'f1': []}, float('inf')\n",
    "        for epoch in range(n_epochs):\n",
    "            loss = self.train_step(train_loader, epoch, grad_clip)\n",
    "            val_loss, predictions = self.validate(valid_loader, epoch)\n",
    "            em_score, f1_score = metrics(predictions)\n",
    "            history['loss'].append(loss); history['val_loss'].append(val_loss)\n",
    "            history['em'].append(em_score); history['f1'].append(f1_score)\n",
    "            if best_loss > val_loss:\n",
    "                best_loss = val_loss\n",
    "                torch.save(self.model.state_dict(), './checkpoints/DrQA.pth')\n",
    "            time.sleep(1)\n",
    "            print(f'\\nEM={em_score:.3f}% - F1={f1_score:.3f}%')\n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b8617e",
   "metadata": {
    "id": "kFzM-vWUAov9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "***Train the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa871c98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:36:31.608206Z",
     "iopub.status.busy": "2022-06-20T22:36:31.605757Z",
     "iopub.status.idle": "2022-06-20T22:36:31.617655Z",
     "shell.execute_reply": "2022-06-20T22:36:31.615687Z",
     "shell.execute_reply.started": "2022-06-20T22:36:31.608158Z"
    },
    "id": "-YCmJQLhAlqo",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_LAYERS = 3\n",
    "EMBED_SIZE = 300\n",
    "HIDDEN_SIZE = 128\n",
    "DROPOUT = 0.3\n",
    "N_EPOCHS = 5\n",
    "GRAD_CLIP = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de09ff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:36:31.619864Z",
     "iopub.status.busy": "2022-06-20T22:36:31.619589Z",
     "iopub.status.idle": "2022-06-20T22:36:31.789925Z",
     "shell.execute_reply": "2022-06-20T22:36:31.788437Z",
     "shell.execute_reply.started": "2022-06-20T22:36:31.619829Z"
    },
    "id": "ersGVmFxBwAV",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drqa = DrQA(vocab_size=len(TEXT),\n",
    "            embedding_size=EMBED_SIZE,\n",
    "            n_extra_features=4,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            n_layers=N_LAYERS,\n",
    "            dropout=DROPOUT,\n",
    "            pad_index=TEXT.stoi(PAD_TOKEN))\n",
    "drqa.load_glove_embeddings('./data/GloVe_DrQA.npy', most_common_indexes, tune=True)\n",
    "drqa.to(DEVICE)\n",
    "optimizer = optim.Adamax(params=drqa.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TEXT.stoi(PAD_TOKEN))\n",
    "print(f'Number of parameters of the model: {sum(p.numel() for p in drqa.parameters() if p.requires_grad):,}')\n",
    "print(drqa)\n",
    "trainer = Trainer(model=drqa, optimizer=optimizer, criterion=criterion, id_field=ID, text_field=TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f208a22f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:36:31.792743Z",
     "iopub.status.busy": "2022-06-20T22:36:31.792483Z",
     "iopub.status.idle": "2022-06-20T22:37:03.799502Z",
     "shell.execute_reply": "2022-06-20T22:37:03.798638Z",
     "shell.execute_reply.started": "2022-06-20T22:36:31.792708Z"
    },
    "id": "giP1Ov5_DTGr",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./checkpoints\n",
    "history = trainer.train(train_loader=train_dataloader, valid_loader=valid_dataloader, n_epochs=N_EPOCHS, grad_clip=GRAD_CLIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5770e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:37:03.801939Z",
     "iopub.status.busy": "2022-06-20T22:37:03.801347Z",
     "iopub.status.idle": "2022-06-20T22:37:04.363873Z",
     "shell.execute_reply": "2022-06-20T22:37:04.363084Z",
     "shell.execute_reply.started": "2022-06-20T22:37:03.801887Z"
    },
    "id": "8C-bSJpY-qZM",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(history['loss'], label='train')\n",
    "axes[0].plot(history['val_loss'], label='valid')\n",
    "axes[0].set_title('Loss history')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history['em'], label='valid')\n",
    "axes[1].set_title('Exact match history')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Exact match (%)')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(history['f1'], label='valid')\n",
    "axes[2].set_title('F1 history')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('F1 (%)')\n",
    "axes[2].grid(True)\n",
    "axes[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b3d67",
   "metadata": {
    "id": "Z_99dtAVn5CL",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "***Inference***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbd746e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:37:04.365429Z",
     "iopub.status.busy": "2022-06-20T22:37:04.365047Z",
     "iopub.status.idle": "2022-06-20T22:37:04.434290Z",
     "shell.execute_reply": "2022-06-20T22:37:04.433576Z",
     "shell.execute_reply.started": "2022-06-20T22:37:04.365395Z"
    },
    "id": "Gk9dSwSR_OM9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drqa.load_state_dict(torch.load('./checkpoints/DrQA.pth'))\n",
    "drqa.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68048479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:37:04.436278Z",
     "iopub.status.busy": "2022-06-20T22:37:04.435794Z",
     "iopub.status.idle": "2022-06-20T22:37:04.456797Z",
     "shell.execute_reply": "2022-06-20T22:37:04.455801Z",
     "shell.execute_reply.started": "2022-06-20T22:37:04.436243Z"
    },
    "id": "p1CVgakLDtsU",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model: nn.Module, context: spacy.tokens.doc.Doc, question: spacy.tokens.doc.Doc,\n",
    "              text_vocab: Vocab, pos_vocab: Vocab, ner_vocab: Vocab, device: torch.device):\n",
    "    # Build extra features\n",
    "    question = [token.text.lower() for token in question]\n",
    "    counts = collections.Counter(map(lambda token: token.text.lower(), context))\n",
    "    freqs = {index: counts[token.text.lower()] for index, token in enumerate(context)}\n",
    "    freqs_norm = sum(freqs.values())\n",
    "    em, pos, ner, ntf = zip(\n",
    "        *map(lambda index: [\n",
    "            context[index].text.lower() in question, context[index].tag_,\n",
    "            context[index].ent_type_ or 'None',\n",
    "            freqs[index] / freqs_norm\n",
    "        ], range(len(context)))\n",
    "    )\n",
    "\n",
    "    # Build tensors\n",
    "    ctx = torch.LongTensor([*map(lambda word: text_vocab.stoi(word), context)]).unsqueeze(0).to(device)\n",
    "    qst = torch.LongTensor([*map(lambda word: text_vocab.stoi(word), question)]).unsqueeze(0).to(device)\n",
    "    len_ctx = torch.LongTensor([len(context)]).to(device)\n",
    "    len_qst = torch.LongTensor([len(question)]).to(device)\n",
    "    em = torch.LongTensor(em).unsqueeze(0).to(device)\n",
    "    pos = torch.LongTensor([*map(lambda x: pos_vocab.stoi(x), pos)]).unsqueeze(0).to(device)\n",
    "    ner = torch.LongTensor([*map(lambda x: ner_vocab.stoi(x), ner)]).unsqueeze(0).to(device)\n",
    "    ntf = torch.LongTensor(ntf).unsqueeze(0).to(device)\n",
    "\n",
    "    # Prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Feed the model\n",
    "        start, end = model(ctx_sequences=ctx, ctx_lengths=len_ctx, qst_sequences=qst, qst_lengths=len_qst,\n",
    "                           em_sequences=em, pos_sequences=pos, ner_sequences=ner, ntf_sequences=ntf)\n",
    "    \n",
    "        # Decode the result indexes\n",
    "        start_index, end_index, proba = model.__class__.decode(starts=F.softmax(start, dim=-1), ends=F.softmax(end, dim=-1))\n",
    "\n",
    "        # Extract the answer\n",
    "        answer = context[start_index[0]:end_index[0] + 1]\n",
    "\n",
    "    return answer, proba[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd380c0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-20T22:37:04.458648Z",
     "iopub.status.busy": "2022-06-20T22:37:04.458090Z",
     "iopub.status.idle": "2022-06-20T22:37:07.437627Z",
     "shell.execute_reply": "2022-06-20T22:37:07.436788Z",
     "shell.execute_reply.started": "2022-06-20T22:37:04.458608Z"
    },
    "id": "dI-ME2Q1-WzB",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index in np.random.choice(len(valid_qas), size=25, replace=False):\n",
    "    id = valid_qas[index]['id']\n",
    "    context = valid_qas[index]['context']\n",
    "    question = valid_qas[index]['question']\n",
    "\n",
    "    answers = []\n",
    "    for qa in valid_qas:\n",
    "        if id == qa['id']:\n",
    "            answers.append(qa['answer'])\n",
    "\n",
    "    prediction, proba = inference(model=drqa, context=context, question=question,\n",
    "                                  text_vocab=TEXT, pos_vocab=POS, ner_vocab=NER, device=DEVICE)\n",
    "    \n",
    "    html = f'<p><span><b>Context:</b> {context.text}</span><br />'\n",
    "    html += f'<span><b>Question:</b> {question.text}</span><br />'\n",
    "    html += f'<span style=\"color:blue\"><b>Possible answers:</b><br /><ul>'\n",
    "    for answer in answers:\n",
    "        html += f'<li style=\"color:blue\">{answer.text}</li>'\n",
    "    html += '</ul></span><br />'\n",
    "    html += f'<span style=\"color:green\"><b>Prediction:</b> {prediction}</span><br />'\n",
    "    html += f'<span style=\"color:green\"><b>Probability:</b> {proba * 100:.3f}%</span><br />'\n",
    "    display(HTML(html))\n",
    "    print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b17b17",
   "metadata": {
    "id": "v7JFJMsaEQAL",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 110.685622,
   "end_time": "2022-06-20T23:22:23.466863",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-20T23:20:32.781241",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
